{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 모델을 학습시키기 위해 준비되어야 할 4가지 요소\n",
    "\n",
    "**1. 데이터**\n",
    "2. 모델\n",
    "3. 손실 함수(목적함수, objective function, loss function 등으로 불려요): 정답과 모델의 예측값을 어떤 식으로 비교할지 결정해주는 함수\n",
    "4. optimizer: gradient descent를 해줄 애. 즉, 모델의 파라미터를 어느 방향으로 조금 수정할지 결정하고 수정해주는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 : Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scipy==0.19.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import display, Image\n",
    "from scipy import ndimage\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from six.moves import cPickle as pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in Ipython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 다운로드 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://commondatastorage.googleapis.com/books1000/'\n",
    "\n",
    "data_root = './data'\n",
    "if not os.path.exists(data_root):\n",
    "    os.mkdir(data_root)\n",
    "    \n",
    "def dataset_downloader(filename):\n",
    "    \"\"\"데이터셋 파일이 없으면 다운로드 합니다.\"\"\"\n",
    "    dest_dir = os.path.join(data_root, filename)\n",
    "    if not os.path.exists(dest_dir):\n",
    "        print('다운로드 시도 중 : ', filename)\n",
    "        filename, _ = urlretrieve(url + filename, dest_dir)\n",
    "        print(filename, ' 다운로드 완료!')\n",
    "    else:\n",
    "        print(dest_dir, ' 이미 있습니다.')\n",
    "    \n",
    "    return dest_dir\n",
    "\n",
    "train_filename = dataset_downloader('notMNIST_large.tar.gz')\n",
    "test_filename = dataset_downloader('notMNIST_small.tar.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다운로드한 데이터 압축 풀기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "np.random.seed(1000)\n",
    "\n",
    "def data_extract(filename):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]  # remove .tar.gz\n",
    "    \n",
    "    if os.path.isdir(root):\n",
    "        print('{} 이미 있습니다 - {} 는 추출을 건너뜁니다.'.format(root, filename))\n",
    "    else:\n",
    "        print('{} 에서 데이터를 추출합니다.'.format(root))\n",
    "        tar = tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(data_root)\n",
    "        tar.close()\n",
    "    data_folders = [\n",
    "        os.path.join(root, d) for d in sorted(os.listdir(root))\n",
    "        if os.path.isdir(os.path.join(root, d))]\n",
    "    \n",
    "    if len(data_folders) != num_classes:\n",
    "        raise Exception('{} folders 기대했는데, {} 개가 있네요.'.format(num_classes, len(data_folders)))\n",
    "    \n",
    "    print(data_folders)\n",
    "    return data_folders\n",
    "\n",
    "train_folders = data_extract(train_filename)\n",
    "test_folders = data_extract(test_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 글자 데이터를 로드해서 pickle 파일 형태로 저장하기\n",
    "주의: 개인 노트북 컴퓨터일 경우 오래 걸릴 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "\n",
    "def load_letter(folder):\n",
    "    \"\"\"한 글자 클래스 데이터를 로드합니다.\"\"\"\n",
    "    image_files = os.listdir(folder)\n",
    "    dataset = np.ndarray(shape=(len(image_files), image_size, image_size), dtype=np.float32)\n",
    "    \n",
    "    num_images = 0\n",
    "    for image in image_files:\n",
    "        image_file = os.path.join(folder, image)\n",
    "        try:\n",
    "            image_data = (ndimage.imread(image_file).astype(float) - pixel_depth / 2) / pixel_depth  # image 픽셀값의 범위를 0~1로 만들어줍니다.\n",
    "            if image_data.shape != (image_size, image_size):\n",
    "                raise Exception('이미지가 이상한 크기인데요?: {}'.format(str(image_data.shape)))\n",
    "            dataset[num_images, :, :] = image_data\n",
    "            num_images = num_images + 1\n",
    "        except IOError as e:\n",
    "            print('{} - skip'.format(e))\n",
    "    \n",
    "    dataset = dataset[0:num_images, :, :]\n",
    "    print('전체 데이터셋 모양은 다음과 같습니다:', dataset.shape)\n",
    "    \n",
    "    return dataset\n",
    "        \n",
    "def make_pickle(data_folders):\n",
    "    dataset_names = []\n",
    "    for folder in data_folders:\n",
    "        set_filename = folder + '.pickle'\n",
    "        dataset_names.append(set_filename)\n",
    "        if os.path.exists(set_filename):\n",
    "            print('{} 이미 있습니다 - pickling을 건너뜁니다.'.format(set_filename))\n",
    "            continue\n",
    "        print('Pickling {}'.format(set_filename))\n",
    "        dataset = load_letter(folder)\n",
    "        with open(set_filename, 'wb') as f:\n",
    "            pickle.dump(dataset, f)\n",
    "\n",
    "    return dataset_names\n",
    "\n",
    "train_datasets = make_pickle(train_folders)\n",
    "test_datasets = make_pickle(test_folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 이미지 예시 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in tqdm(range(len(train_datasets))):\n",
    "    set_filename = train_datasets[i]\n",
    "    with open(set_filename, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    images.append(dataset[1])\n",
    "print(np.shape(images))\n",
    "\n",
    "Row = 2\n",
    "Column = 5\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(Row, Column, i+1)\n",
    "    plt.title('Label = {}'.format(os.path.basename(train_datasets[i])[0]))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 트레이닝셋, 테스트셋 개수 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"==== 트레이닝셋을 위한 데이터들 ====\")\n",
    "for i in range(len(train_datasets)):\n",
    "    set_filename = train_datasets[i]\n",
    "    with open(set_filename, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    print(\"글자 {} 에 대한 트레이닝 데이터 개수는 {} 개입니다.\".format(os.path.basename(set_filename)[0], len(dataset)))\n",
    "\n",
    "print(\"\\n==== 테스트셋을 위한 데이터들 =====\")\n",
    "for i in range(len(test_datasets)):\n",
    "    set_filename = test_datasets[i]\n",
    "    with open(set_filename, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    print(\"글자 {} 에 대한 테스트 데이터 개수는 {} 개입니다.\".format(os.path.basename(set_filename)[0], len(dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 각 글자 별로 나뉘어져있던 데이터를 합쳐서 트레이닝셋, 테스트셋 2개로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_datasets(pickle_files, dataset_size):\n",
    "    num_classes = len(pickle_files)\n",
    "    dataset = np.ndarray((dataset_size, image_size, image_size), dtype=np.float32)\n",
    "    labels = np.ndarray(dataset_size, dtype=np.int32)\n",
    "    tsize_per_class = dataset_size // num_classes\n",
    "\n",
    "    start_t = 0\n",
    "    end_t = tsize_per_class\n",
    "    for label, pickle_file in enumerate(pickle_files):       \n",
    "        with open(pickle_file, 'rb') as f:\n",
    "            letter_set = pickle.load(f)\n",
    "            np.random.shuffle(letter_set)\n",
    "\n",
    "            letter = letter_set[0:tsize_per_class, :, :]\n",
    "            dataset[start_t:end_t, :, :] = letter\n",
    "            labels[start_t:end_t] = label\n",
    "            start_t += tsize_per_class\n",
    "            end_t += tsize_per_class\n",
    "\n",
    "    return dataset, labels\n",
    "\n",
    "train_size = 200000\n",
    "test_size = 10000\n",
    "\n",
    "train_dataset, train_labels = merge_datasets(train_datasets, train_size)\n",
    "test_dataset, test_labels = merge_datasets(test_datasets, test_size)\n",
    "\n",
    "print('Training:', train_dataset.shape, train_labels.shape)\n",
    "print('Testing:', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 섞어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(dataset, labels):\n",
    "    permutation = np.random.permutation(labels.shape[0])\n",
    "    shuffled_dataset = dataset[permutation,:,:]\n",
    "    shuffled_labels = labels[permutation]\n",
    "    return shuffled_dataset, shuffled_labels\n",
    "\n",
    "train_dataset, train_labels = shuffle(train_dataset, train_labels)\n",
    "test_dataset, test_labels = shuffle(test_dataset, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 섞은 후에 다시 한 번 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Row = 2\n",
    "Column = 5\n",
    "ListOfLabel = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "\n",
    "print(\"==== 트레이닝 데이터 예시 ====\")\n",
    "images = train_dataset[0:10]\n",
    "labels = train_labels[0:10]\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(Row, Column, i+1)\n",
    "    plt.title('Label = {}'.format(ListOfLabel[labels[i]]))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print(\"==== 테스트 데이터 예시 ====\")\n",
    "images = test_dataset[0:10]\n",
    "labels = test_labels[0:10]\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(Row, Column, i+1)\n",
    "    plt.title('Label = {}'.format(ListOfLabel[labels[i]]))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 파일로 내보내기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = os.path.join(data_root, 'notMNIST.pickle')\n",
    "\n",
    "f = open(pickle_file, 'wb')\n",
    "save = {\n",
    "    'train_dataset': train_dataset[:50000,],\n",
    "    'train_labels': train_labels[:50000,],\n",
    "    'test_dataset': test_dataset[:5000,],\n",
    "    'test_labels': test_labels[:5000,],\n",
    "}\n",
    "pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 모델을 학습시키기 위해 준비되어야 할 4가지 요소\n",
    "\n",
    "**1. 데이터**\n",
    "\n",
    "2. 모델\n",
    "3. 손실 함수(목적함수, objective function, loss function 등으로 불려요): 정답과 모델의 예측값을 어떤 식으로 비교할지 결정해주는 함수\n",
    "4. Optimizer: gradient descent를 해줄 애. 즉, 모델의 파라미터를 어느 방향으로 조금 수정할지 결정하고 수정해주는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: PyTorch를 이용해서 Convolutional Neural Network 정의해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from six.moves import range\n",
    "from six.moves import cPickle as pickle\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델에 데이터 넣을 준비하기\n",
    "\n",
    "우선 사용하고 싶은 데이터 파일이 있다면 \n",
    "1. 그걸 우선 numpy array 형식으로 불러와야 해요.\n",
    "2. 그리고는 필요한 전처리를 해준 후에 \n",
    "3. 이 numpy array를 `torch.*Tensor` 형식으로 변환하고 \n",
    "4. dataloader에 넣어주면 pytorch로 짠 딥러닝 모델에 넣을 준비가 된 거예요.\n",
    "\n",
    "대개 이제 이런 데이터 처리를 도와주는 패키지들이 있는데<br/>\n",
    "이미지는 openCV, Pillow를 많이 쓰고,<br/>\n",
    "텍스트에는 SpaCy를 많이 사용합니다. <br/>\n",
    "\n",
    "여기서는 매우 간단한 이미지 데이터를 사용하므로 별도의 패키지를 쓰지는 않을게요 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 데이터셋 불러오기\n",
    "\n",
    "이미 앞서서 numpy형식으로 저장을 해뒀죠? <br/>\n",
    "그러니까 그냥 로드만 해주면 됩니다. <br/>\n",
    "고마워 pickle! <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_file = 'data/notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    test_dataset = save['test_dataset']\n",
    "    test_labels = save['test_labels']\n",
    "    del save  # garbage collector(gc)에게 \"이거 지워도 된단다\"라고 넌지시 알려주기 \n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ~심심하니까~ 이미지 한 번 더 확인해줍니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Row = 2\n",
    "Column = 5\n",
    "classes = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "\n",
    "print(\"==== 트레이닝 데이터 예시 ====\")\n",
    "rand = random.randint(0, 29989)  # 그냥 아무 랜덤한 이미지들을 뽑아내기 위해서 index 역할을 해줄 숫자 하나를 뽑아볼게요.\n",
    "images = train_dataset[rand:rand+10]\n",
    "labels = train_labels[rand:rand+10]\n",
    "print(labels)\n",
    "for i, image in enumerate(images):\n",
    "    plt.subplot(Row, Column, i+1)\n",
    "    plt.title('Label = {}'.format(classes[labels[i]]))\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28  # notMNIST 데이터는 이미지 크기가 28x28이였죠?\n",
    "num_labels = 10  # 클래스 개수는 10개구요.\n",
    "\n",
    "# 트레이닝셋, 테스트셋 이미지들의 차원 배치를 좀 바꿔줍니다.\n",
    "# Batch_dim, Channel_dim, Height, Width: BCHW라고 줄여서 말하기도 합니다. 또는 NCHW\n",
    "x_train = train_dataset.reshape(-1, 1, 28, 28)  # 왜 1일까요?\n",
    "x_test = test_dataset.reshape(-1, 1, 28, 28)\n",
    "\n",
    "y_train = train_labels\n",
    "y_test = test_labels\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. tensor로 바꿔주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.tensor(x_train)\n",
    "y_train = torch.tensor(y_train, dtype=torch.int64)\n",
    "\n",
    "x_test = torch.tensor(x_test)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. data loader에 넣어주기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "test_set = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "\n",
    "batch_size = 16\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 이미지 예시 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # 아까 앞에서 normalize해줘서 색깔 이미지가 이상해져있을 거기 때문에 보기 편하라고 다시 unnormalize해줍니다\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "# print labels\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 모델을 학습시키기 위해 준비되어야 할 4가지 요소\n",
    "\n",
    "1. 데이터\n",
    "\n",
    "**2. 모델**\n",
    "3. Loss function (손실함수, 목적함수, objective function 등으로 불려요): 정답과 모델의 예측값을 어떤 식으로 비교할지 결정해주는 함수\n",
    "4. Optimizer: gradient descent를 해줄 애. 즉, 모델의 파라미터를 어느 방향으로 조금 수정할지 결정하고 수정해주는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 3x3 square convolution\n",
    "        self.conv1 = nn.Conv2d(1, 6, 3, stride=1, padding=1)  # yes, zero padding. \n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        ############### TODO: fc layer를 완성 해보세요 ################\n",
    "        \n",
    "        self.fc = nn.Linear(인풋 숫자 , 아웃풋 숫자 )\n",
    "        \n",
    "        ########################################################\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # 위 3줄을 줄여서 표현한 게 아래예요.\n",
    "        # x = self.pool(self.relu(self.conv1(x)))\n",
    "\n",
    "        ############### TODO: 빈칸을 완성 해보세요 ################\n",
    "        \n",
    "        x = x.view(-1, 여긴 뭐가 들어가야 할까요)  # 얘의 기능은 텐서의 모양을 원하는 모양으로 바꿔주는 거예요\n",
    "        # 예시: x가 만약 (16, 3, 12, 12) 모양이었다면 x.view(-1, 144)는 (48, 144) 모양으로 바꿔준답니다. -1은 나머지 숫자를 자동으로 채워주는 역할이에요\n",
    "        \n",
    "        ########################################################\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 모델을 학습시키기 위해 준비되어야 할 4가지 요소\n",
    "\n",
    "1. 데이터\n",
    "2. 모델\n",
    "\n",
    "**3. Loss function (손실함수, 목적함수, objective function 등으로 불려요)**: 정답과 모델의 예측값을 어떤 식으로 비교할지 결정해주는 함수\n",
    "\n",
    "**4. Optimizer**: gradient descent를 해줄 애. 즉, 모델의 파라미터를 어느 방향으로 조금 수정할지 결정하고 수정해주는 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss function과 Optimizer 정의하기\n",
    "\n",
    "Cross-entropy loss function과 SGD optimizer를 씁니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 학습시키기\n",
    "\n",
    "이제\n",
    "* data loader\n",
    "* model\n",
    "* loss function\n",
    "* optimizer\n",
    "\n",
    "이 4가지가 모두 준비되었으니 학습을 할 준비가 끝났습니다.\n",
    "\n",
    "```\n",
    "종료 조건 만족할 때까지 아래를 반복:\n",
    "    1. 우리의 data loader로부터 데이터를 받아와서 모델에 넣어주고\n",
    "    2. 모델의 출력 값을 받아서 \n",
    "    3. loss function 값을 계산하고\n",
    "    4. 그 loss를 바탕으로 backprop(=gradient를 계산) 해준 뒤 \n",
    "    5. optimizer가 gradient descent를 1 step 진행합니다.\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []  # 우리 모델이 어떻게 학습되는지, loss가 잘 떨어지는지 확인하기 위해 매 step loss를 저장해놓을 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(2):  # 전체 데이터셋을 몇 번 반복할 건지\n",
    "\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # data에는 이미지와 정답 라벨이 들어있죠?\n",
    "        inputs, labels = data\n",
    "        \n",
    "        # 매 반복마다 이전 gradient를 한 번 지워줍니다.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 모델에 데이터 넣어서 forward 해주고 \n",
    "        # backprop(=backward)으로 이번 input에 대해 gradient를 계산해주고\n",
    "        # optimizer가 gradient descent 1스텝 진행\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 결과치 화면에 뿌려주기\n",
    "        running_loss += loss.item()\n",
    "        if i % 300 == 299:    \n",
    "            \n",
    "            # 300 미니배치마다 트레이닝셋에 대한 loss값 출력\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 300))\n",
    "            \n",
    "            # 나중에 시각화를 위해 중간중간 따로 loss값 저장\n",
    "            loss_history.append(running_loss / 300)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('학습 끝!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습 경과 살펴보기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "사실 저렇게 출력된 숫자들만 보면 감이 잘 오지 않는 거 같아요 그쵸?<br/>\n",
    "그래서 그래프로 트레이닝셋에 대해 loss가 잘 떨어지는지 살펴보는 게 필요해요<br/>\n",
    "우리가 방금 위에서 정의한 loss_history 배열에는 학습 중간중간 저장해놓았던 트레이닝셋에 대한 loss 값들이 있어요. <br/>\n",
    "얘를 시각화 해볼게요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history) \n",
    "plt.title('Training Loss', fontsize=20)  # 여기에 한글을 넣고 싶으시다구요? 그럼 좀 귀찮은 몇 가지 작업들을 해야 합니다... 그러므로 패스\n",
    "plt.xlabel('Iteration',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장하기\n",
    "\n",
    "학습이 끝난 모델의 파라미터를 저장해두면 나중에 필요할 때 불러와서 가져다 쓰면 바로 사용할 수 있어요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './notmnist_net.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 테스트셋에 검증해보기\n",
    "\n",
    "이제 모델 학습이 끝났으니 테스트 데이터에도 잘하는지 확인을 해봐야 합니다. <br/>\n",
    "테스트셋 데이터 중 몇 개나 맞히는지 알아볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트셋 이미지 예시도 심심풀이로 한 번 확인해보기\n",
    "# functions to show an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # 아까 앞에서 normalize해줘서 색깔 이미지가 이상해져있을 거기 때문에 보기 편하라고 다시 unnormalize해줍니다\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 아까 저장해뒀던 모델 파라미터 불러오기\n",
    "\n",
    "사실 굳이 불러오지 않고 그냥 위에 있는 `net` 그대로 써도 되지만 <br/>\n",
    "일단 어떻게 저장하고 불러오는지 여러분이 알아둬야 하니까 여기서는 `net`에 굳이 다시 불러와봤어요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 불러온 모델로 예측해보기\n",
    "\n",
    "이미지들을 넣었을 때 모델이 뭐라고 예측하는지 한 번 확인해볼게요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "뭔지 전혀 모르겠죠? <br/>\n",
    "각 row에 있는 숫자들은 10개의 클래스에 대한 logit 값이에요. (확률 값이 아니라) <br/>\n",
    "어떤 인덱스의 logit값이 크면 모델은 그 해당 인덱스의 클래스로 해당 이미지를 분류한다는 의미입니다. <br/>\n",
    "따라서 그냥 이 logit 값들 중 제일 큰 logit이 있는 index를 각 row마다 뽑아오면 됩니다. <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predicted = torch.max(outputs, 1)  # 1번째 차원(=각 row)에서 각각 max인 값과 해당 index를 뽑아옵니다.\n",
    "\n",
    "classes = ['A', 'B', 'C', 'D', 'E', 'F','G', 'H', 'I', 'J']\n",
    "\n",
    "print('모델 예측: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 역시 원래 이미지랑 같이 봐야 감이 올 거 같죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(torchvision.utils.make_grid(images[:8]))\n",
    "print('실제 정답: ', ' '.join('%5s' % classes[labels[j]] for j in range(8)))\n",
    "print('모델 예측: ', ' '.join('%5s' % classes[predicted[j]]\n",
    "                              for j in range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "매우 잘 맞히는 거 같습니다! <br/>\n",
    "그러면 이제 전체 테스트셋에 대해 정답과 비교해서 몇 개나 맞히는지 보겠습니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 테스트셋 정답률 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('10000개의 테스트 이미지에 대한 정답률: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 각 클래스 별 정답률 확인해보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "with torch.no_grad():  # 매우매우 중요! 테스트셋으로 학습하는 건 반칙입니다. 테스트셋으로 backprop을 하면 안 되지요.\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(4):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "for i in range(10):\n",
    "    print('%5s 클래스의 정답률 : %2d %%' % (\n",
    "        classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 끝!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
